# -*- coding: utf-8 -*-
"""4_22299050_22299049.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eOJa7YBCCVqmIKKLBz6GNPV73eUcfpRG
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

"""# Dataset"""

# loading dataset
df = pd.read_csv('/content/heart_disease.csv')

# Display a few examples from the training data
df.head()

"""## Dataset description"""

# 1. Determine the number of features and data points
print(f"Shape of the dataset: {df.shape}")
print(f"Number of data points: {df.shape[0]}")
print(f"Number of features: {df.shape[1]}")

# 2. Get a concise summary of the DataFrame
df.info()

# 3. Determine if it's a classification or regression problem based on the 'num' column
print("\nAnalyzing the 'num' column to determine the problem type:")
print(df['num'].value_counts())

"""## Categorical and Numerical feature analysis and finding target column

Identifying and examining the categorical columns to determine the need for encoding.
"""

print("Column names:", list(df.columns))
categorical_cols = df.select_dtypes(include='object').columns
print("Categorical columns:")
print(categorical_cols)

print("\nNumber of unique values in each categorical column:")
for col in categorical_cols:
    unique_values = df[col].nunique()
    print(f"{col}: {unique_values} unique values")

numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns
print("Numerical Columns:")
print(numerical_columns)

print("\nNumber of unique values in each numerical column:")
for col in numerical_columns:
    unique_values = df[col].nunique()
    print(f"{col}: {unique_values} unique values")
print("Target column 'num' values:", df['num'].unique())

"""# Calculating Correlation Matrix and Drawing Correlation Heatmap"""

# Calculate the correlation matrix
correlation_matrix = df.corr(numeric_only=True)
print(correlation_matrix)

# Create a heatmap of the correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")

# Add a title to the heatmap
plt.title("Correlation Matrix of Features")

# Display the heatmap
plt.show()

"""## Correlation interpretation

**Reasoning**:

Examine the heatmap and the correlation matrix dataframe to identify strong correlations and summarize the key findings, focusing on the target variable 'num'.
"""

# Examine the correlation matrix, especially the correlations with the target variable 'num'
print("Correlation with the target variable 'num':")
print(correlation_matrix['num'].sort_values(ascending=False))
# Calculate the value counts for the target variable 'num'
num_column_distribution = df['num'].value_counts()

# Print the value counts
print("Class distribution of the target variable 'num':")
print(num_column_distribution)

"""# Class Distribution of Target('num')"""

# Create a bar chart visualizing the class distribution of num column
plt.figure(figsize=(8, 6))
sns.barplot(x=num_column_distribution.index, y=num_column_distribution.values)

# Add appropriate labels and title
plt.xlabel("Heart Disease Presence (0 --> No Disease, 1-4 --> Disease)")
plt.ylabel("Number of Patients")
plt.title("Distribution of Heart Disease Presence")

# Display the bar chart
plt.show()

"""### Exploratory data analysis (eda)

**Reasoning**:

Create visualizations to explore relationships between features as instructed.
"""

# Scatter plot for 'age' vs 'thalch' colored by target column num
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='age', y='thalch', hue='num', palette='viridis', alpha=0.6)
plt.title('Age vs. Max Heart Rate Achieved (thalch) by Heart Disease Presence')
plt.xlabel('Age')
plt.ylabel('Max Heart Rate Achieved (thalch)')
plt.show()

"""# Box plots for numerical features"""

# Box plots for numerical features across different 'num' categories - 0, 1, 2, 3, 4
numerical_features = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']
plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_features):
    plt.subplot(2, 3, i + 1)
    sns.boxplot(data=df, x='num', y=col, palette='viridis')
    plt.title(f'{col} Distribution by Heart Disease Presence')
    plt.xlabel('Heart Disease Presence')
    plt.ylabel(col)
plt.tight_layout()
plt.show()

"""# Count plots for categorical features"""

# Count plots for categorical features in relation to 'num'
categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']

plt.figure(figsize=(15, 15))
for i, col in enumerate(categorical_features):
    plt.subplot(3, 3, i + 1)
    sns.countplot(data=df, x=col, hue='num', palette='viridis')
    plt.title(f'{col} Distribution by Heart Disease Presence')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability
plt.tight_layout()
plt.show()

"""Explore relationships between Important features"""

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.scatterplot(data=df, x='ca', y='oldpeak', hue='num', palette='viridis', alpha=0.6)
plt.title('CA vs. Oldpeak by Heart Disease Presence')
plt.xlabel('Number of Major Vessels (ca)')
plt.ylabel('ST Depression (oldpeak)')

plt.subplot(1, 2, 2)
sns.scatterplot(data=df, x='age', y='ca', hue='num', palette='viridis', alpha=0.6)
plt.title('Age vs. CA by Heart Disease Presence')
plt.xlabel('Age')
plt.ylabel('Number of Major Vessels (ca)')

plt.tight_layout()
plt.show()

"""## Data preprocessing - faults

**Reasoning**:

Print the number of missing values per column, identify columns with missing values, list object type columns, and discuss implications.
"""

# Print the number of missing values per column and identify columns with missing values
print("Missing values per column:")
missing_values = df.isnull().sum()
print(missing_values[missing_values > 0])

# List columns of object type and confirm they are categorical
print("\nObject type columns (categorical):")
object_columns = df.select_dtypes(include='object').columns
print(object_columns)

"""**Data preprocessing - solutions**
**Reasoning**:

Apply the specified imputation techniques for numerical and categorical columns, confirming the data types for 'ca' and 'thal' before imputation. Then, apply one-hot encoding to the identified categorical columns, excluding 'dataset' as justified by potential noise from combining datasets. Finally, apply standard scaling to the numerical features (excluding the target 'num' and dummy variables) and verify the processed DataFrame.

"""

# Step 1: Handle missing values (Replacing Numerical Columns with missing values)
#median karon less affected by outliers, otherwise knn, regression model kaaj korbe nah
numerical_cols_imputation = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca']
for col in numerical_cols_imputation:
    if col in df.columns and df[col].isnull().any():
        median_val = df[col].median()
        df[col] = df[col].fillna(median_val)  # Corrected: removed inplace=True
        print(f"Imputed missing values in '{col}' with median: {median_val}")

# categorical columns jekhane missing values ache, missing values replaced by mode (most frequent value),
# frequent value make sense to fill in, otherwise knn, regression kaaj korbe na
categorical_cols_imputation = ['fbs', 'restecg', 'exang', 'slope', 'thal']  # 'thal' is categorical
for col in categorical_cols_imputation:
    if col in df.columns and df[col].isnull().any():
        mode_val = df[col].mode()[0]
        df[col] = df[col].fillna(mode_val)  # Corrected: removed inplace=True
        print(f"Imputed missing values in '{col}' with mode: {mode_val}")
# Verify missing values after imputation
print("\nMissing values after imputation:")
print(df.isnull().sum()[df.isnull().sum() > 0])

# Step 2 & 3: Handle categorical variables and the 'dataset' column
# Identify categorical columns for encoding. Exclude 'dataset'.
categorical_cols_encode = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']

# Drop the 'dataset' column
if 'dataset' in df.columns:
    df = df.drop('dataset', axis=1)
    print("\nDropped the 'dataset' column.")
# Apply one-hot encoding
cols_to_encode_present = [col for col in categorical_cols_encode if col in df.columns]
df = pd.get_dummies(df, columns=cols_to_encode_present, drop_first=True)

# Step 4: Apply scaling
# Identify numerical features for scaling. Exclude 'id' and 'num'.
# After imputation and encoding, the numerical columns to scale are the original ones
# that were not one-hot encoded, plus 'ca'.
numerical_cols_scale = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']
# Filter out columns like id, num should not be scaled
numerical_cols_scale = [col for col in numerical_cols_scale if col in df.columns and col not in ['id', 'num']]

# Apply scaling
if numerical_cols_scale:
    scaler = StandardScaler()
    df[numerical_cols_scale] = scaler.fit_transform(df[numerical_cols_scale])
    print("\nApplied Standard Scaling to numerical features:", numerical_cols_scale)

#shows 1st 5 rows
print("\nProcessed DataFrame head:")
print(df.head())

#total missing values in the dataframe
print("\nMissing values after all preprocessing steps:")
print(df.isnull().sum().sum())  # Should be 0

"""## Dataset splitting"""

# input/features inside x and target/output in y
x = df.drop('num', axis=1)
y = df['num']

# Split data into training and testing sets with stratification
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=50, stratify=y)

print("Shape of x_train:", x_train.shape)
print("Shape of x_test:", x_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Model training & testing (supervised)"""

# 2. Initialize instances of each selected model
# Neural Network (MLPClassifier)
neural_network_model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42)

# K-Nearest Neighbors (KNN)
k_nearest_model = KNeighborsClassifier(n_neighbors=5)  # Using 5 neighbors

# Logistic Regression
logistic_regression_model = LogisticRegression(max_iter=1000, random_state=42)  # Increased max_iter for convergence




# 3. Train each model
neural_network_model.fit(x_train, y_train)
k_nearest_model.fit(x_train, y_train)
logistic_regression_model.fit(x_train, y_train)


# 4. Make predictions on the test data
neural_network_prediction = neural_network_model.predict(x_test)
k_nearest_prediction = k_nearest_model.predict(x_test)
logistic_regression_prediction = logistic_regression_model.predict(x_test)

# 5. Evaluate the performance of each model and print results
print("\n--- Neural Network Evaluation ---")
print("Accuracy:", round(accuracy_score(y_test, neural_network_prediction), 5))
print("Classification Report:\n", classification_report(y_test, neural_network_prediction))

print("\n--- KNN Evaluation ---")
print("Accuracy:", round(accuracy_score(y_test, k_nearest_prediction), 5))
print("Classification Report:\n", classification_report(y_test, k_nearest_prediction))

print("\n--- Logistic Regression Evaluation ---")
print("Accuracy:", round(accuracy_score(y_test, logistic_regression_prediction), 5))
print("Classification Report:\n", classification_report(y_test, logistic_regression_prediction))

"""## Model training & testing (unsupervised)"""

# 2. Instantiate a KMeans object
kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)

# 3. Fit the K-Means model to the features (X)
# Use the full feature set X, not just X_train or X_test
kmeans.fit(x)

# 4. Get the cluster labels
cluster_labels = kmeans.labels_

# 5. Add the cluster labels to a copy of the DataFrame X for visualization
X_clustered = x.copy()
X_clustered['kmeans_cluster'] = cluster_labels

# 6. Visualize the clusters using a scatter plot of 'age' vs 'thalch'
plt.figure(figsize=(10, 6))
sns.scatterplot(data=X_clustered, x='age', y='thalch', hue='kmeans_cluster', palette='viridis', alpha=0.6)

# 7. Add a title and labels to the scatter plot
plt.title('K-Means Clustering of Heart Disease Data (Age vs. Thalch)')
plt.xlabel('Age (Scaled)')
plt.ylabel('Max Heart Rate Achieved (Thalch) (Scaled)')
plt.show()

"""## Model selection/comparison analysis"""

nn_accuracy = accuracy_score(y_test, neural_network_prediction)
knn_accuracy = accuracy_score(y_test, k_nearest_prediction)
lr_accuracy = accuracy_score(y_test, logistic_regression_prediction)

# Create a Pandas Series to store the accuracy scores
accuracy_scores = pd.Series({
    'Neural Network': nn_accuracy,
    'KNN': knn_accuracy,
    'Logistic Regression': lr_accuracy
})

# Sort the scores for better visualization
accuracy_scores = accuracy_scores.sort_values(ascending=False)

# Generate a bar chart to visualize the accuracy comparison
plt.figure(figsize=(12, 7))
sns.barplot(x=accuracy_scores.index, y=accuracy_scores.values, palette='viridis')

# Add title and axis labels
plt.title("Supervised Model Accuracy Comparison")
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.ylim(0, 1)  # Set y-axis limit from 0 to 1 for accuracy
plt.xticks(rotation=45)

# Display the bar chart
plt.show()

print("\n--- Classification Report Comparison ---")

# Function to get a DataFrame from classification report
def classification_report_df(y_true, y_pred, model_name):
    report = classification_report(y_true, y_pred, output_dict=True)
    df_report = pd.DataFrame(report).transpose()
    df_report['model'] = model_name
    return df_report.reset_index().rename(columns={'index': 'class'})

# Get reports for each model
nn_report_df = classification_report_df(y_test, neural_network_prediction, 'Neural Network')
knn_report_df = classification_report_df(y_test, k_nearest_prediction, 'KNN')
lr_report_df = classification_report_df(y_test, logistic_regression_prediction, 'Logistic Regression')
# Concatenate all reports into a single DataFrame
all_reports_df = pd.concat([nn_report_df, knn_report_df, lr_report_df])


# Display the reports for each class across models
print("\nPrecision Comparison:")
precision_comparison = all_reports_df[all_reports_df['class'].isin(['0', '1', '2', '3', '4'])].pivot(index='class', columns='model', values='precision')
print(precision_comparison.round(3))

print("\nRecall Comparison:")
recall_comparison = all_reports_df[all_reports_df['class'].isin(['0', '1', '2', '3', '4'])].pivot(index='class', columns='model', values='recall')
print(recall_comparison.round(3))

print("\nF1-score Comparison:")
f1_comparison = all_reports_df[all_reports_df['class'].isin(['0', '1', '2', '3', '4'])].pivot(index='class', columns='model', values='f1-score')
print(f1_comparison.round(3))

plt.figure(figsize=(12, 7))
macro_f1_scores = all_reports_df[all_reports_df['class'] == 'macro avg'].set_index('model')['f1-score'].sort_values(ascending=False)
sns.barplot(x=macro_f1_scores.index, y=macro_f1_scores.values, palette='viridis')
plt.title("Supervised Model Macro Avg F1-score Comparison")
plt.xlabel("Model")
plt.ylabel("Macro Avg F1-score")
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

# Confusion Matrices
print("\n--- Confusion Matrices ---")

def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {model_name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

models_predictions = {
    'Neural Network': neural_network_prediction,
    'KNN': k_nearest_prediction,
    'Logistic Regression': logistic_regression_prediction
}

for name, predictions in models_predictions.items():
    plot_confusion_matrix(y_test, predictions, name)

print("\n--- AUC/ROC Curve (One-vs-Rest for Class 1) ---")

# Binarize the output for one-vs-rest
y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4])
n_classes = y_test_binarized.shape[1]

plt.figure(figsize=(10, 8))




# Models that support predict_proba for multi-class
models_with_proba = {
    'Neural Network': neural_network_model,
    'KNN': k_nearest_model,
    'Logistic Regression': logistic_regression_model
}

for name, model in models_with_proba.items():
    try:
        y_prob = model.predict_proba(x_test)
        # Compute ROC curve and AUC for each class
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        for i in range(n_classes):
            fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        # Plot ROC curve for class 1 (index 1 in binarized output)
        if 1 in roc_auc:
            plt.plot(fpr[1], tpr[1], label=f'{name} (AUC = {roc_auc[1]:.2f})')
        else:
            print(f"Warning: Could not compute ROC/AUC for class 1 for {name}")

    except AttributeError:
        print(f"Model {name} does not support predict_proba.")
    except ValueError as e:
        print(f"Error computing ROC/AUC for {name}: {e}")

plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve for Class 1 (Presence of Disease)')
plt.legend(loc="lower right")
plt.show()

"""## Summary:

### Data Analysis Key Findings

* The dataset contains 920 data points and 16 features, and the problem is a classification task based on the discrete values in the 'num' column.

* Eight categorical columns ('sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal') were identified, all with a low number of unique values. Several categorical columns, as well as numerical ones, contained missing values.

* The target variable 'num' showed the strongest positive correlations with 'ca' (0.52) and 'oldpeak' (0.44), and a moderate negative correlation with 'thalch' (-0.37).

* The target variable 'num' exhibits class imbalance, with the value 0 being the most frequent class.

* After preprocessing, missing values were imputed (median for numerical, mode for categorical), the 'dataset' column was dropped, categorical variables were one-hot encoded, and numerical features were standard scaled.

* 'Three supervised models (Neural Network, KNN, Logistic Regression) were trained and evaluated.

* K-Means clustering with 5 clusters was applied to the feature set.

### Insights or Next Steps

* The class imbalance in the target variable should be addressed in future modeling steps to improve the performance on minority classes. Techniques like oversampling, undersampling, or using class weights could be explored.

* Further hyperparameter tuning for the supervised models, especially the Neural Network and KNN, could potentially improve their performance. Evaluating other classification metrics (precision, recall, F1-score) is crucial, particularly given the class imbalance and the warnings about ill-defined metrics observed in the initial evaluation.

"""


